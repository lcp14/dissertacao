{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-15T02:23:27.369804Z",
     "start_time": "2019-03-15T02:23:26.898931Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import unicodedata\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-15T02:23:27.393215Z",
     "start_time": "2019-03-15T02:23:27.386108Z"
    }
   },
   "outputs": [],
   "source": [
    "def remove_non_ascii_word(word):\n",
    "    \"\"\"Remove non-ASCII characters from list of tokenized words\"\"\"\n",
    "    new_word = unicodedata.normalize('NFKD', word).encode('ascii', 'ignore').decode('utf-8', 'ignore')\n",
    "    \n",
    "    return new_word\n",
    "def hasAuthor(string):\n",
    "    return autoresID.loc[autoresID['nome'] == string]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-15T07:42:47.398373Z",
     "start_time": "2019-03-15T07:42:47.392909Z"
    }
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('h2.pickle', 'rb') as f:\n",
    "    W = pickle.load(f)\n",
    "W = W.transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-15T02:23:27.570016Z",
     "start_time": "2019-03-15T02:23:27.510254Z"
    }
   },
   "outputs": [],
   "source": [
    "df_artigos = pd.read_csv('../../datasets/artigos/preprocessed/without_spacy/artigos2017_pre',sep=\"|\",index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-15T02:23:29.466370Z",
     "start_time": "2019-03-15T02:23:29.242986Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7411\n"
     ]
    }
   ],
   "source": [
    "autoresID = pd.read_csv('../../datasets/autores/autores.csv', delimiter=\"|\")\n",
    "autoresID.columns=['id','nome','path']\n",
    "print(len(autoresID['nome'].unique()))\n",
    "autoresID.shape\n",
    "autoresID['nome'] = autoresID['nome'].apply(remove_non_ascii_word)\n",
    "autoresID['nome'] = autoresID['nome'].apply(lambda x: x.lower().rstrip().lstrip())\n",
    "autoresCIT = pd.read_csv('../../datasets/autores/autor_cit.csv',delimiter=\"|\")\n",
    "autoresCIT.columns=['id','nome_cit']\n",
    "autoresCIT['nome_cit'] = autoresCIT['nome_cit'].apply(lambda x: x.rstrip().lstrip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-15T07:43:59.180728Z",
     "start_time": "2019-03-15T07:42:49.828436Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "autor_topic = {}\n",
    "autor_qt = {}\n",
    "miss_author = 0\n",
    "for idx_doc,doc in enumerate(W):\n",
    "    autores = df_artigos.iloc[idx_doc]['autores']\n",
    "    tempA = []\n",
    "    for autor in autores.split(\"&\"):\n",
    "        autor = remove_non_ascii_word(autor.lower())\n",
    "        dfAuthorName = hasAuthor(autor)\n",
    "        if len(dfAuthorName) != 0:\n",
    "            autorCod = dfAuthorName.iloc[0]['id'].item()\n",
    "            if autor not in tempA:\n",
    "                tempA.append(autorCod)\n",
    "                if autorCod not in autor_topic.keys():\n",
    "                    autor_topic[autorCod] = doc\n",
    "                    autor_qt[autorCod] = 1\n",
    "                else:\n",
    "                    autor_topic[autorCod] += doc\n",
    "                    autor_qt[autorCod] += 1\n",
    "\n",
    "\n",
    "        else:\n",
    "            df_autor_id = autoresCIT.loc[autoresCIT['nome_cit'] == autor]['id']\n",
    "            if len(df_autor_id) != 0:\n",
    "                autor_id = df_autor_id.item()\n",
    "                autor = autoresID.loc[autoresID['id']==autor_id]['nome'].item()\n",
    "                autor = remove_non_ascii_word(autor.lower())\n",
    "                if autor not in tempA:\n",
    "                    tempA.append(autor_id)\n",
    "                    if autor_id not in autor_topic.keys():\n",
    "                        autor_topic[autor_id] = doc\n",
    "                        autor_qt[autor_id] = 1\n",
    "                    else:\n",
    "                        autor_topic[autor_id] += doc\n",
    "                        autor_qt[autor_id] += 1\n",
    "            #else:\n",
    "                #if autor not in tempA:\n",
    "                 #   tempA.append(autor)\n",
    "                  #  if autor not in autor_topic.keys():\n",
    "                   #     autor_topic[autor] = doc\n",
    "                    #    autor_qt[autor] = 1\n",
    "                    #else:\n",
    "                     #   autor_topic[autor] += doc + 1\n",
    "                      #  autor_qt[autor] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-15T07:44:01.595920Z",
     "start_time": "2019-03-15T07:44:01.591541Z"
    }
   },
   "outputs": [],
   "source": [
    "autor_topic_relevance_matrix = [autor_topic[key] for key in autor_topic.keys()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-15T07:44:05.074085Z",
     "start_time": "2019-03-15T07:44:05.038969Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leandror/.local/lib/python3.6/site-packages/ipykernel_launcher.py:3: RuntimeWarning: invalid value encountered in true_divide\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "a_topic_relevance_matrix_normalized = []\n",
    "for vec in autor_topic_relevance_matrix:\n",
    "    vec = vec/max(vec)\n",
    "    a_topic_relevance_matrix_normalized.append(vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-15T07:44:09.058453Z",
     "start_time": "2019-03-15T07:44:09.041391Z"
    }
   },
   "outputs": [],
   "source": [
    "most_relevant_author_in_topic_matrix_normalized = []\n",
    "autor_topic_relevance_matrix = np.array(autor_topic_relevance_matrix)\n",
    "for vec in autor_topic_relevance_matrix.transpose():\n",
    "    vec1 = vec/max(vec)\n",
    "    most_relevant_author_in_topic_matrix_normalized.append(vec1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-15T07:44:13.420416Z",
     "start_time": "2019-03-15T07:44:11.995017Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "table_topic_autor = []\n",
    "for id_top in range(len(most_relevant_author_in_topic_matrix_normalized)):\n",
    "    for i in np.argsort(-np.array(most_relevant_author_in_topic_matrix_normalized)[id_top]):\n",
    "        id_autor, rank = list(autor_topic.keys())[i],most_relevant_author_in_topic_matrix_normalized[id_top][i]\n",
    "        rank = rank * 100\n",
    "        table_topic_autor.append([id_autor,rank,'2017','2017'+str(id_autor)+str(id_top),id_top+1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-15T07:44:16.746985Z",
     "start_time": "2019-03-15T07:44:16.308935Z"
    }
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(table_topic_autor).to_csv('topic_autor_h2',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-15T07:44:20.043056Z",
     "start_time": "2019-03-15T07:44:19.651152Z"
    }
   },
   "outputs": [],
   "source": [
    "table_autor_topic = []\n",
    "for idx,i in enumerate(a_topic_relevance_matrix_normalized):\n",
    "    autor_id = list(autor_topic.keys())[idx]\n",
    "    for id_topic,j in enumerate(i):\n",
    "        if np.isnan(j):\n",
    "            j = 0\n",
    "        j = j*100\n",
    "        table_autor_topic.append([autor_id,j,id_topic+1,'2017',str(autor_id)+str(id_topic+1)+'2017'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-15T07:44:23.423097Z",
     "start_time": "2019-03-15T07:44:23.004316Z"
    }
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(table_autor_topic).to_csv('autor_topic_h2',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
